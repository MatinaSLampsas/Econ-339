---
title: "ECON 339 - Tuesday/Thursday Week 6"
date: "May 9, 2024"
author: "Matina Lampsas"
format: 
   html:
     embed-resources: true
     code-tools: true
     toc: true
     code-fold: show
     output-ext: github_document 
editor: source
execute: 
  error: true
  echo: true
  message: false
  warning: false
  
---

# Setup
```{r setup}
library(tidyverse)
library(readxl)
options(scipen = 999)

```
# Tuesday Notes
## Read in the Data 
```{r}
#read in the data for the wages 
wages_data <- read_xlsx(here::here("data",
                     "Data for Weeks 2-7.xlsx"), 
                      sheet = "Wages"
                     )
```

## In Class Example:
### Make a scatter plot: 
Plot Wage against Age and evaluate whether a linear or quadratic regression 
model better captures the relationship. Verify your choice by using the 
appropriate goodness-of-fit measure.
```{r}
wages_data %>% 
  ggplot(aes(x = Age, y = Wage))+
  geom_jitter()+ 
  geom_smooth()+ 
  geom_smooth(method = "lm", color = "red")
```
* On the exam, he will ask us to do graphs

Use the appropriate model to predict hourly wages for someone with 16 
years of education and age equal to 30, 50, or 70
### Conduct/predict using lm: 
```{r}
wages_data <- wages_data %>% 
  mutate(age_sqrd = Age^2)
wages_lm <- lm(Wage ~ Age + Educ ,data = wages_data)
summary(wages_lm)
wages_qm <- lm(Wage ~ Educ+ Age + I(Age^2), data = wages_data)
summary(wages_qm)

```
### Predict Vals: 
```{r}
predict(wages_qm, data.frame(Educ=16, Age=30))
predict(wages_qm, data.frame(Educ=16, Age=50))
predict(wages_qm, data.frame(Educ=16, Age=70))

```
NOTE TO SELF --> FIND A WAY TO DO THIS WITHOUT THE I() THING
According to the model, at what age will someone with 16 years of 
education attain the highest wages?

### Make visualization:
```{r}
coeffs <- coefficients(wages_qm)
predict <- map2_df(.x = 20:80,
                   .y= 16,
                   .f = ~predict(wages_qm, data.frame(Educ = .y, Age = .x)))
predict %>%
  mutate(age = 20:80) %>%
  rename(pred_wage = `1`) %>%
  ggplot(aes(x = age, y = pred_wage)) +
  geom_jitter() +
  geom_smooth(color = "blue", aes(group = "Quadratic Model")) +  # Labeling the blue line as quadratic
  geom_smooth(method = "lm", color = "red", aes(group = "Linear Model")) +  # Labeling the red line as linear
  labs(title = "Predicted Quad/Linear graph", x = "Age", y = "Predicted Wage", color = "Model Key")
```

## Practice Question: 
### Import the Data: 
```{r}
#read in the data for the tech sales 
techsales_data <- read_xlsx(here::here("data",
                     "Data for Weeks 2-7.xlsx"), 
                      sheet = "TechSales"
                     )
```

### Subsest the data and make dummy variables: 
First subset the TechSales data to include only hardware product. You should obtain 9860 
observations. Use College and Personality variables to construct appropriate dummy 
variables. 
```{r}
filtered_tchsales <- techsales_data %>% 
  filter(Business == "Hardware") %>% 
  mutate(d1 = if_else(Personality == "Diplomat",1,0),
         d2 = if_else(Personality == "Explorer", 1,0),
         d3 = if_else(Personality == "Analyst",1,0),
         d4 = if_else(Personality == "Sentinel",1,0),
         d5 = if_else(College =="Yes", 1,0))

```
Compare the linear model (Model 1) that uses Age, Female, College, Analyst, 
Diplomat, Explorer, and Certificates as predictor variables. Model 2 extends Model 1 by 
including age-sq as an additional predictor variable
```{r}

# make a model that isn't quadratic
model_1 <- lm(NPS ~ Age + Female +Certificates + d1 + d2 + d3 + d5, data = filtered_tchsales)
# make a quadratic model that considers Age ^2
model_2 <- lm(NPS ~ Age + Female +Certificates+ d1 + d2 + d3 + d5 + I(Age^2), data = filtered_tchsales)
# summarize and compare the models
summary(model_1) ; summary(model_2)

```

• Use model selection criteria to find the appropriate model for the analysis. 
• Interpret your results with reference to well-formatted figures and tables.

```{r}
# Extract coefficients and standard errors
summary_df <- broom::tidy(model_1) %>%
  select(term, estimate, std.error) %>%
  rename(Variable = term, Coefficient = estimate, `Std. Error` = std.error)




# Print or display the summary table
print(summary_df)


```


The second model will be chosen since the R^2 value is larger and theremore more accurate

### Second Part of Practice Question:
Create a plot to highlight the quadratic effect of age. For the plot, use age between 30-60, using a female graduate analyst with 3 certificates

```{r}
# predict the values 
predict_2 <- map_df(.x = 30:60,
                    .f = ~predict(model_2, data.frame(Age = .x, 
                                                      Female = 1, 
                                                      d1 = 0,
                                                      d2 = 0,
                                                      d3 = 1,
                                                      d5 = 1,
                                                      Certificates = 3
                                                      )
                                  )
                    )

predict_2 %>%
  # add an age column to the data
  mutate(age = 30:60) %>%
  #rename the column from the predicted varaible
  rename(pred_NPS = `1`) %>%
  # make the visualization
  ggplot(aes(x = age, y = pred_NPS)) +
  geom_jitter() +
  geom_smooth(color = "blue",aes( fill = "Quadratic Model"), se=FALSE) +  # Labeling the blue line as quadratic
  geom_smooth(method = "lm", color = "red", aes(fill = "Linear Model"), se=FALSE) +  # Labeling the red line as linear
  labs(title = "Predicted Quad/Linear graph", x = "Age", y = "Predicted Wage", color = "Model Key") 

```
# Thursday notes
## Import data 
```{r}
#read in the data for the wages 
collegetwn_data <- read_xlsx(here::here("data",
                     "Data for Weeks 2-7.xlsx"), 
                      sheet = "CollegeTown"
                     )
```

## In Class Example:
### Make a scatter plot: 
Plot Wage against Age and evaluate whether a linear or quadratic regression 
model better captures the relationship. Verify your choice by using the 
appropriate goodness-of-fit measure.
```{r}
# visualize the data - using log transformation 
collegetwn_data %>% 
  ggplot(aes(x = Sqft, y = Rent))+
  geom_jitter()+
  geom_smooth(method = "lm", 
              formula = y ~ log(x), 
              se = FALSE) 

```
** Review the way of doing it on excel **

### Make your models
```{r}
# Model 1 -- standard linear model: 
college_lm <- lm(Rent ~ Beds + Baths + Sqft, data = collegetwn_data)

# Model 2 -- log the sqft and keeping the others constant 
college_lm2 <- lm(Rent ~ Beds + Baths + log(Sqft), data = collegetwn_data)

# Model 3 -- log the rent only and keeping the others constant 
college_lm3 <- lm(log(Rent) ~ Beds + Baths + Sqft, data = collegetwn_data)

# Model 4 -- log the Sqft AND rent and keeping the others constant 
college_lm4 <- lm(log(Rent) ~ Beds + Baths + log(Sqft), data = collegetwn_data)


```

### Made predictions using your models: 
#### Use model 1 & 2 to make predictions
```{r}
#use model 1 to make a prediction with sqft = 1600, Beds = 3, and Baths = 2
predict(college_lm, data.frame(Beds = 3, 
                               Baths = 2,
                               Sqft = 1600))
#use model 2 to make a prediction with sqft = 1600, Beds = 3, and Baths = 2
predict(college_lm2, data.frame(Beds = 3, 
                               Baths = 2,
                               Sqft = 1600))

```
#### Use model 3 to make prediction
```{r}
# use the model 3 to predict
# since rent (y) is logged, you need to compute the se in order to predicti: use the following steps

predi_log_3 <- predict(college_lm3, data.frame(Beds = 3, 
                                               Baths = 2,
                                               Sqft = 1600))

# extract the standard error of the linear model
se_3 <- sigma(college_lm3)
# use the standard error and you prediction in order to predict that value 
prediction_model_3 <- exp(predi_log_3 + se_3^2/2)

prediction_model_3
```


#### Use model 4 to make prediction
```{r}
# use the model 4 to predict
# since rent (y) is logged, you need to compute the se in order to predicti: use the following steps
predi_log_4 <- predict(college_lm4, data.frame(Beds = 3, 
                                               Baths = 2,
                                               Sqft = 1600))
# extract the standard error of the linear model
se_4 <- sigma(college_lm4)
# use the standard error and you prediction in order to predict that value 
prediction_model_4 <- exp(predi_log_4 + se_4^2/2)

prediction_model_4

```

#### Comparing Models 2 and 4: 
We need to compute R^2 from scratch 
```{r}
# computing Rsq for model 4; 
predict_lnrent <- predict(college_lm4)
stde_4 <- sigma(college_lm4)
pred_rent <- exp(predict_lnrent+stde_4^2/2)
cor(collegetwn_data$Rent, pred_rent)^2
```

#### Write a function to compute R^2: 
```{r}
compute_r_squared <- function(model, var, data) {
  # Compute predicted log value
  predict_lnval <- predict(model)
  
  # Compute standard error of the model
  stde <- sigma(model)
  
  # Compute predicted value
  pred_val <- exp(predict_lnval + stde^2 / 2)
  
  # Compute R-squared
  r_squared <- cor(data[[var]], pred_val)^2
  
  return(r_squared)
}

# Example usage:
# Replace 'college_lm4' with your actual linear model and 'collegetwn_data' with your dataset
result <- compute_r_squared(model = college_lm4, var = "Rent", data = collegetwn_data)
cat("R-squared for model 4:", result, "\n")

```
## Class Practice Problems
### Problem 2: 
2. A business division is a part of a company that is responsible for a specific product, service, or 
market. Business divisions are often set up to allow a company to focus on a particular area of 
its operations and to operate more efficiently. The accompanying data file includes employee 
salary (Salary, in $1,000s), business division (Marketing, Development, or Customer Service) 
and college education (Yes or No). Data: Division.
```{r}
#read in the data for the wages 
division_data <- read_xlsx(here::here("data",
                     "Data for Weeks 2-7.xlsx"), 
                      sheet = "Division"
                     )
```

#### Part 1: 
• Use the appropriate dummy variables to estimate a linear regression model for salary 
using business division and college education as predictor variables. Use the estimated 
model to predict the salaries of college educated employees in each of the three divisions. 

```{r}
# Make dummy varaiables 
division_data <- division_data %>% 
  mutate(d1 = if_else(Division == "Marketing",1,0),
         d2 = if_else(Division == "Development", 1,0),
         d3 = if_else(Division == "Customer Service",1,0),
         d4 = if_else(College =="Yes", 1,0))

# estimate a linear regression model for salary using business division and college education as predictor variables
division_lm <- lm(Salary ~ d1 +d2 + d4, data = division_data)
# summary(division_lm)

#use the model to predict the salary of college educated employees in each of the three divisions
## prediction for marketing
predict(division_lm, data.frame(d1 = 1, d2=0, d4=1))
## prediction for development
predict(division_lm, data.frame(d1 = 0, d2=1, d4=1))
## prediction for customer service
predict(division_lm, data.frame(d1 = 0, d2=0, d4=1))

```

#### Part 2: 
• Find the corresponding predictions using an exponential model that uses ln(Salary) as the 
response variable. 
```{r}
#| code-fold: true
# Write function to do prediction easy: 
predict_and_calculate <- function(d1, d2, d4, model) {
  # Predict the log value
  predi_log <- predict(model, newdata = data.frame(d1 = d1, d2 = d2, d4 = d4))
  
  # Extract the standard error
  se <- sigma(model)
  
  # Calculate the final prediction
  prediction <- exp(predi_log + se^2 / 2)
  
  return(prediction)
}


```


```{r}
# estimate a linear model for salary using exponential model that uses ln(Salary as response)
division_exp <- lm(log(Salary) ~ d1 +d2 + d4, data = division_data)


predict_and_calculate(d1 = 1, d2 = 0, d4 = 1, model = division_exp)
predict_and_calculate(d1 = 0, d2 = 1, d4 = 1, model = division_exp)
predict_and_calculate(d1 = 0, d2 = 1, d4 = 1, model = division_exp)


```

#### Part 3: 
• Which of the above is a more appropriate predictive model?
```{r}
# we need to calculate R^2 if we want to compare the models
compute_r_squared(model = division_exp, var = "Salary", data = division_data)
```

